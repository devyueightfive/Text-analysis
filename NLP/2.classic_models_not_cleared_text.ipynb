{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from imblearn.pipeline import Pipeline as pipeline_imb\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "PATH_TO_DATA = './simplesentiment/'\n",
    "files = ['products_sentiment_train.tsv', 'products_sentiment_test.tsv']\n",
    "train =  pd.read_csv(PATH_TO_DATA+files[0], sep = '\\t', header = None, names = ['text', 'target'])\n",
    "# train, taget, test\n",
    "data_samples = train.text.values\n",
    "y = train.target\n",
    "test = pd.read_csv(PATH_TO_DATA+files[1], sep = '\\t')\n",
    "test_samples = test.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data\n",
    "def split_data(X, y, rs):\n",
    "    test_portion = 0.33\n",
    "    return train_test_split(X,\n",
    "                            y,\n",
    "                            test_size=test_portion,\n",
    "                            random_state=int(rs),\n",
    "                            shuffle=True,\n",
    "                            stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,v, yx, yv = split_data(data_samples, y , 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# data transformer - vectorizer\n",
    "count_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=1,\n",
    "    tokenizer=word_tokenize,\n",
    "    analyzer='word',\n",
    ")\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=1,\n",
    "    tokenizer=word_tokenize,\n",
    "    analyzer='word',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from some_funcs import checking\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = ComplementNB(alpha=0.5)\n",
    "logit = LogisticRegression(penalty='l2', C=1.0)\n",
    "svm = SVC(C=1.0, kernel='rbf', probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with BOW f1: 0.8436\n",
      "Naive Bayes with BOW accuracy: 0.7848\n",
      "Naive Bayes with BOW roc_auc: 0.8386\n",
      "\n",
      "Logistic Regression with BOW f1: 0.8246\n",
      "Logistic Regression with BOW accuracy: 0.7576\n",
      "Logistic Regression with BOW roc_auc: 0.8301\n",
      "\n",
      "SVC with BOW f1: 0.8059\n",
      "SVC with BOW accuracy: 0.6985\n",
      "SVC with BOW roc_auc: 0.8217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_name = \"BOW\"\n",
    "\n",
    "data_x = [vect.fit(x).transform(x) for vect in [count_vectorizer]]\n",
    "data_v = [vect.fit(x).transform(v) for vect in [count_vectorizer]]\n",
    "\n",
    "union_x = hstack(data_x)\n",
    "union_v = hstack(data_v)\n",
    "\n",
    "for cls_name, cls in zip(['Naive Bayes', 'Logistic Regression', 'SVC'],\n",
    "                          [nb, logit, svm]):\n",
    "    cls.fit(union_x, yx)\n",
    "    pred = cls.predict(union_v)\n",
    "    prob = cls.predict_proba(union_v)[:, 1]\n",
    "    print(f\"{cls_name} with {features_name} f1: {f1_score(yv, pred).round(4)}\")\n",
    "    print(f\"{cls_name} with {features_name} accuracy: {accuracy_score(yv, pred).round(4)}\")\n",
    "    print(f\"{cls_name} with {features_name} roc_auc: {roc_auc_score(yv, prob).round(4)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ...\n",
      "f1\n",
      "(array([0.8462, 0.8561, 0.8609, 0.8351, 0.8259]), 0.8448, 0.013)\n",
      "done in 1.173s.\n",
      "\n",
      "Cross-validation ...\n",
      "accuracy\n",
      "(array([0.79  , 0.7975, 0.815 , 0.77  , 0.765 ]), 0.7875, 0.0183)\n",
      "done in 1.117s.\n",
      "\n",
      "Cross-validation ...\n",
      "roc_auc\n",
      "(array([0.8571, 0.8729, 0.8626, 0.8317, 0.8338]), 0.8516, 0.0162)\n",
      "done in 1.229s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_bow = Pipeline(steps=[('bow', count_vectorizer), ('cls', nb)])\n",
    "checking(pipe_bow, data_samples, y, 10, n_jobs=-1, scoring='f1', cv=5)\n",
    "checking(pipe_bow, data_samples, y, 10, n_jobs=-1, scoring='accuracy', cv=5)\n",
    "checking(pipe_bow, data_samples, y, 10, n_jobs=-1, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ...\n",
      "f1\n",
      "(array([0.8309, 0.852 , 0.8466, 0.8388, 0.8364]), 0.841, 0.0075)\n",
      "done in 2.451s.\n",
      "\n",
      "Cross-validation ...\n",
      "accuracy\n",
      "(array([0.77  , 0.7925, 0.7925, 0.78  , 0.78  ]), 0.783, 0.0086)\n",
      "done in 2.634s.\n",
      "\n",
      "Cross-validation ...\n",
      "roc_auc\n",
      "(array([0.8482, 0.8359, 0.8556, 0.8518, 0.8483]), 0.848, 0.0066)\n",
      "done in 2.441s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_bow = Pipeline(steps=[('bow', count_vectorizer), ('cls', logit)])\n",
    "checking(pipe_bow, data_samples, y, 10, n_jobs=-1, scoring='f1', cv=5)\n",
    "checking(pipe_bow, data_samples, y, 10, n_jobs=-1, scoring='accuracy', cv=5)\n",
    "checking(pipe_bow, data_samples, y, 10, n_jobs=-1, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ...\n",
      "f1\n",
      "(array([0.8126, 0.7947, 0.8085, 0.8066, 0.818 ]), 0.8081, 0.0078)\n",
      "done in 8.434s.\n",
      "\n",
      "Cross-validation ...\n",
      "accuracy\n",
      "(array([0.7175, 0.69  , 0.7075, 0.705 , 0.7275]), 0.7095, 0.0126)\n",
      "done in 8.700s.\n",
      "\n",
      "Cross-validation ...\n",
      "roc_auc\n",
      "(array([0.8   , 0.8134, 0.8326, 0.8217, 0.818 ]), 0.8171, 0.0107)\n",
      "done in 8.638s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_bow = Pipeline(steps=[('bow', count_vectorizer), ('cls', svm)])\n",
    "checking(pipe_bow, data_samples, y, 10, n_jobs=-1, scoring='f1', cv=5)\n",
    "checking(pipe_bow, data_samples, y, 10, n_jobs=-1, scoring='accuracy', cv=5)\n",
    "checking(pipe_bow, data_samples, y, 10, n_jobs=-1, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = ComplementNB(alpha=0.5).fit(union_x, yx)\n",
    "prob_bow = cls.predict_proba(union_v)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes with TFIDF f1: 0.8221\n",
      "Naive Bayes with TFIDF accuracy: 0.7364\n",
      "Naive Bayes with TFIDF roc_auc: 0.8524\n",
      "\n",
      "Logistic Regression with TFIDF f1: 0.8058\n",
      "Logistic Regression with TFIDF accuracy: 0.697\n",
      "Logistic Regression with TFIDF roc_auc: 0.8588\n",
      "\n",
      "SVC with TFIDF f1: 0.7985\n",
      "SVC with TFIDF accuracy: 0.6803\n",
      "SVC with TFIDF roc_auc: 0.8608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_name = \"TFIDF\"\n",
    "\n",
    "data_x = [vect.fit(x).transform(x) for vect in [tf_vectorizer]]\n",
    "data_v = [vect.fit(x).transform(v) for vect in [tf_vectorizer]]\n",
    "\n",
    "union_x = hstack(data_x)\n",
    "union_v = hstack(data_v)\n",
    "\n",
    "for cls_name, cls in zip(['Naive Bayes', 'Logistic Regression', 'SVC'],\n",
    "                          [nb, logit, svm]):\n",
    "    cls.fit(union_x, yx)\n",
    "    pred = cls.predict(union_v)\n",
    "    prob = cls.predict_proba(union_v)[:, 1]\n",
    "    print(f\"{cls_name} with {features_name} f1: {f1_score(yv, pred).round(4)}\")\n",
    "    print(f\"{cls_name} with {features_name} accuracy: {accuracy_score(yv, pred).round(4)}\")\n",
    "    print(f\"{cls_name} with {features_name} roc_auc: {roc_auc_score(yv, prob).round(4)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ...\n",
      "f1\n",
      "(array([0.8303, 0.8204, 0.8342, 0.8202, 0.8325]), 0.8275, 0.006)\n",
      "done in 3.327s.\n",
      "\n",
      "Cross-validation ...\n",
      "accuracy\n",
      "(array([0.7475, 0.7275, 0.7575, 0.7325, 0.7525]), 0.7435, 0.0116)\n",
      "done in 2.434s.\n",
      "\n",
      "Cross-validation ...\n",
      "roc_auc\n",
      "(array([0.8668, 0.8786, 0.8571, 0.8558, 0.8578]), 0.8632, 0.0086)\n",
      "done in 1.178s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_tf = Pipeline(steps=[('tf', tf_vectorizer), ('cls', nb)])\n",
    "checking(pipe_tf, data_samples, y, 10, n_jobs=-1, scoring='f1', cv=5)\n",
    "checking(pipe_tf, data_samples, y, 10, n_jobs=-1, scoring='accuracy', cv=5)\n",
    "checking(pipe_tf, data_samples, y, 10, n_jobs=-1, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ...\n",
      "f1\n",
      "(array([0.8104, 0.8071, 0.821 , 0.8071, 0.8176]), 0.8126, 0.0057)\n",
      "done in 1.891s.\n",
      "\n",
      "Cross-validation ...\n",
      "accuracy\n",
      "(array([0.7075, 0.7   , 0.7275, 0.7025, 0.72  ]), 0.7115, 0.0106)\n",
      "done in 1.805s.\n",
      "\n",
      "Cross-validation ...\n",
      "roc_auc\n",
      "(array([0.8533, 0.8559, 0.8741, 0.8571, 0.8678]), 0.8616, 0.0079)\n",
      "done in 1.847s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_tf = Pipeline(steps=[('tf', tf_vectorizer), ('cls', logit)])\n",
    "checking(pipe_tf, data_samples, y, 10, n_jobs=-1, scoring='f1', cv=5)\n",
    "checking(pipe_tf, data_samples, y, 10, n_jobs=-1, scoring='accuracy', cv=5)\n",
    "checking(pipe_tf, data_samples, y, 10, n_jobs=-1, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ...\n",
      "f1\n",
      "(array([0.8096, 0.7981, 0.8096, 0.8019, 0.8076]), 0.8054, 0.0046)\n",
      "done in 8.900s.\n",
      "\n",
      "Cross-validation ...\n",
      "accuracy\n",
      "(array([0.7025, 0.6825, 0.7025, 0.69  , 0.6975]), 0.695, 0.0077)\n",
      "done in 9.240s.\n",
      "\n",
      "Cross-validation ...\n",
      "roc_auc\n",
      "(array([0.8592, 0.8607, 0.8799, 0.8592, 0.8645]), 0.8647, 0.0079)\n",
      "done in 9.079s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_tf = Pipeline(steps=[('tf', tf_vectorizer), ('cls', svm)])\n",
    "checking(pipe_tf, data_samples, y, 10, n_jobs=-1, scoring='f1', cv=5)\n",
    "checking(pipe_tf, data_samples, y, 10, n_jobs=-1, scoring='accuracy', cv=5)\n",
    "checking(pipe_tf, data_samples, y, 10, n_jobs=-1, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = svm.fit(union_x, yx)\n",
    "prob_tf = cls.predict_proba(union_v)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF and BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = [vect.fit(x).transform(x) for vect in [count_vectorizer, tf_vectorizer]]\n",
    "data_v = [vect.fit(x).transform(v) for vect in [count_vectorizer, tf_vectorizer]]\n",
    "union_x = hstack(data_x)\n",
    "union_v = hstack(data_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ...\n",
      "f1\n",
      "(array([0.8451, 0.8434, 0.8582, 0.8345, 0.8303]), 0.8423, 0.0096)\n",
      "done in 4.856s.\n",
      "\n",
      "Cross-validation ...\n",
      "accuracy\n",
      "(array([0.78  , 0.7725, 0.8025, 0.765 , 0.765 ]), 0.777, 0.0139)\n",
      "done in 4.309s.\n",
      "\n",
      "Cross-validation ...\n",
      "roc_auc\n",
      "(array([0.8542, 0.867 , 0.8569, 0.827 , 0.8316]), 0.8474, 0.0154)\n",
      "done in 2.655s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('union',\n",
    "                        FeatureUnion(transformer_list=[(\n",
    "                            'bow', count_vectorizer), ('tfidf',\n",
    "                                                       tf_vectorizer)],\n",
    "                                     n_jobs=-1)), \n",
    "                       ('cls', nb)])\n",
    "checking(pipe, data_samples, y, 10, n_jobs=-1, scoring='f1', cv=5)\n",
    "checking(pipe, data_samples, y, 10, n_jobs=-1, scoring='accuracy', cv=5)\n",
    "checking(pipe, data_samples, y, 10, n_jobs=-1, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ...\n",
      "f1\n",
      "(array([0.8339, 0.852 , 0.8466, 0.8388, 0.8364]), 0.8416, 0.0067)\n",
      "done in 6.610s.\n",
      "\n",
      "Cross-validation ...\n",
      "accuracy\n",
      "(array([0.775 , 0.7925, 0.7925, 0.78  , 0.78  ]), 0.784, 0.0072)\n",
      "done in 6.470s.\n",
      "\n",
      "Cross-validation ...\n",
      "roc_auc\n",
      "(array([0.8488, 0.8366, 0.8565, 0.8527, 0.849 ]), 0.8487, 0.0067)\n",
      "done in 6.700s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('union',\n",
    "                        FeatureUnion(transformer_list=[(\n",
    "                            'bow', count_vectorizer), ('tfidf',\n",
    "                                                       tf_vectorizer)],\n",
    "                                     n_jobs=-1)), \n",
    "                       ('cls', logit)])\n",
    "checking(pipe, data_samples, y, 10, n_jobs=-1, scoring='f1', cv=5)\n",
    "checking(pipe, data_samples, y, 10, n_jobs=-1, scoring='accuracy', cv=5)\n",
    "checking(pipe, data_samples, y, 10, n_jobs=-1, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ...\n",
      "f1\n",
      "(array([0.8126, 0.7947, 0.8072, 0.8066, 0.818 ]), 0.8078, 0.0078)\n",
      "done in 19.398s.\n",
      "\n",
      "Cross-validation ...\n",
      "accuracy\n",
      "(array([0.7175, 0.69  , 0.705 , 0.705 , 0.7275]), 0.709, 0.0127)\n",
      "done in 19.571s.\n",
      "\n",
      "Cross-validation ...\n",
      "roc_auc\n",
      "(array([0.8021, 0.8144, 0.8335, 0.8229, 0.8192]), 0.8184, 0.0103)\n",
      "done in 18.244s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('union',\n",
    "                        FeatureUnion(transformer_list=[(\n",
    "                            'bow', count_vectorizer), ('tfidf',\n",
    "                                                       tf_vectorizer)],\n",
    "                                     n_jobs=-1)), \n",
    "                       ('cls', svm)])\n",
    "checking(pipe, data_samples, y, 10, n_jobs=-1, scoring='f1', cv=5)\n",
    "checking(pipe, data_samples, y, 10, n_jobs=-1, scoring='accuracy', cv=5)\n",
    "checking(pipe, data_samples, y, 10, n_jobs=-1, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bow = Pipeline(steps=[('bow', count_vectorizer), ('cls', nb)])\n",
    "pipe_tf = Pipeline(steps=[('tf', tf_vectorizer), ('cls', svm)])\n",
    "pipe = Pipeline(steps=[('union',\n",
    "                        FeatureUnion(transformer_list=[(\n",
    "                            'bow', count_vectorizer), ('tfidf',\n",
    "                                                       tf_vectorizer)],\n",
    "                                     n_jobs=-1)), \n",
    "                       ('cls', logit)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ...\n",
      "f1\n",
      "(array([0.8626, 0.8577, 0.8593, 0.8415, 0.8305]), 0.8503, 0.0123)\n",
      "done in 15.971s.\n",
      "\n",
      "Cross-validation ...\n",
      "accuracy\n",
      "(array([0.8175, 0.805 , 0.8125, 0.7825, 0.7775]), 0.799, 0.0161)\n",
      "done in 16.271s.\n",
      "\n",
      "Cross-validation ...\n",
      "roc_auc\n",
      "(array([0.8708, 0.8682, 0.8816, 0.8627, 0.8624]), 0.8691, 0.007)\n",
      "done in 16.387s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_vote = VotingClassifier(estimators=[('bow', pipe_bow), ('tfidf', pipe_tf),\n",
    "                                         ('union', pipe)],\n",
    "                             voting='soft',\n",
    "                             n_jobs=-1)\n",
    "checking(pipe_vote, data_samples, y, 10, n_jobs=-1, scoring='f1', cv=5)\n",
    "checking(pipe_vote, data_samples, y, 10, n_jobs=-1, scoring='accuracy', cv=5)\n",
    "checking(pipe_vote, data_samples, y, 10, n_jobs=-1, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cross-validation ...\n",
    "f1\n",
    "(array([0.8485, 0.8608, 0.8626, 0.8263, 0.822 ]), 0.844, 0.017)\n",
    "done in 16.319s.\n",
    "\n",
    "Cross-validation ...\n",
    "accuracy\n",
    "(array([0.8   , 0.805 , 0.8225, 0.7625, 0.77  ]), 0.792, 0.0224)\n",
    "done in 13.517s.\n",
    "\n",
    "Cross-validation ...\n",
    "roc_auc\n",
    "(array([0.8702, 0.8751, 0.8863, 0.8616, 0.862 ]), 0.871, 0.0092)\n",
    "done in 11.100s.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
